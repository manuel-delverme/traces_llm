TOKEN_CONTEXT_LEN = 16
TEXT_PADDING_ID = 0  # TODO: Change this to the correct padding ID for your tokenizer
GPT2_VOCAB_SIZE = 50257
VOCAB_SIZE = 100
POINTS_IN_MOTOR_SEQUENCE = 64
CHARS_PER_TOKEN = 20
